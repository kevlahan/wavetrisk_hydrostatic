hybrid shared-distributed memory parallelization:
    *	shared-memory: openmp (Fortran does not support pthreds)
	distr.-memory: mpi
    *   mpi: distribute sub-domains as elements (current state)
        openmp: patches as elements
    Remarks:
      - first experiment with openmp + Fortran combination: how to get it work best?
        then integrate into code

try measurement based load-balancing (if tests show that estimating a-priori yields bad results)
    possibly:
       - create data-base in one run so that production runs read from it and do not measure
       - data-base knows time per patch, given
             + patch-size
             + operator type
             + sparsity (patch mostly full or mostly empty)
    note:
       replacing metis with zoltan will only create a different partitioning, given the cost estimate
       (that can be better or worse, *most* likely equally good)
       the difference of the quality of the partitioning will make
           + what parameter passed to the partitioner
           + the correctness of the estimated cost per element (and cost per edge)
             
use multi-constraint partitioning
     every computation between two communication is one constraint
